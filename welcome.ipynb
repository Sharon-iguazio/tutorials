{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Iguazio Data Science Platform\n",
    "\n",
    "An initial introduction to the Iguazio Data Science Platform and the platform tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Platform Overview](#platform-overview)\n",
    "- [Data Science Workflow](#data-science-workflow)\n",
    "- [The Tutorial Notebooks](#the-tutorial-notebooks)\n",
    "- [Getting-Started Tutorial](#getting-started-tutorial)\n",
    "- [End-to-End Use-Case Applications (Demos)](#end-to-end-use-case-applications)\n",
    "- [Installing and Updating the MLRun Python Package](#mlrun-python-pkg-install-n-update)\n",
    "- [Data Ingestion and Preparation](#data-ingestion-and-preparation)\n",
    "- [Additional Platform Resources](#platform-resources)\n",
    "- [Miscellaneous](#misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platform-overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform Overview\n",
    "\n",
    "The Iguazio Data Science Platform (**\"the platform\"**) is a fully integrated and secure data science platform as a service (PaaS), which simplifies development, accelerates performance, facilitates collaboration, and addresses operational challenges.\n",
    "The platform incorporates the following components:\n",
    "\n",
    "- A data science workbench that includes Jupyter Notebook, integrated analytics engines, and Python packages\n",
    "- Model management with experiments tracking and automated pipeline capabilities\n",
    "- Managed data and machine-learning (ML) services over a scalable Kubernetes cluster\n",
    "- A real-time serverless functions framework &mdash; Nuclio\n",
    "- An extremely fast and secure data layer that supports SQL, NoSQL, time-series databases, files (simple objects), and streaming\n",
    "- Integration with third-party data sources such as Amazon S3, HDFS, SQL databases, and streaming or messaging protocols\n",
    "- Real-time dashboards based on Grafana\n",
    "\n",
    "<br><img src=\"./assets/images/igz-self-service-platform.png\" alt=\"Self-service data science platform\" width=\"650\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-science-workflow\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Workflow\n",
    "\n",
    "The platform provides a complete data science workflow in a single ready-to-use platform that includes all the required building blocks for creating data science applications from research to production:\n",
    "\n",
    "- Collect, explore, and label data from various real-time or offline sources\n",
    "- Run ML training and validation at scale over multiple CPUs and GPUs\n",
    "- Deploy models and applications into production with serverless functions\n",
    "- Log, monitor, and visualize all your data and services\n",
    "\n",
    "![Data Science Workflow](./assets/images/igz-data-science-workflow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-tutorial-notebooks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tutorial Notebooks\n",
    "\n",
    "The home directory of the platform's running-user directory (**/User/&lt;running user&gt;**) contains pre-deployed tutorial Jupyter notebooks with code samples and documentation to assist you in your development &mdash; including a [**demos**](demos/README.ipynb) directory with end-to-end use-case applications (see the next section) and a [**data-ingestion-and-preparation**](data-ingestion-and-preparation/README.ipynb) directory with documentation and examples for performing data ingestion and preparation tasks.\n",
    "\n",
    "> **Note:**\n",
    "> - To view and run the tutorials from the platform, you first need to create a Jupyter Notebook service.\n",
    "> - The **welcome.ipynb** notebook and main **README.md** file provide the same introduction in different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-tutorial\"></a>\n",
    "## Getting-Started Tutorial\n",
    "\n",
    "Start out by running the getting-started tutorial to familiarize yourself with the platform and experience firsthand some of its main capabilities.<br>\n",
    "<br>\n",
    "<a href=\"getting-started-tutorial/getting-started-tutorial.ipynb\"><img src=\"./assets/images/view-tutorial-button.png\" alt=\"View tutorial\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"end-to-end-use-case-applications\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Use-Case Applications (Demos)\n",
    "\n",
    "Iguazio provides full end-to-end use-case applications (demos) that demonstrate how to use the platform and related tools to address data science requirements for different industries and implementations.\n",
    "These demos are available in the [MLRun demos repository](https://github.com/mlrun/demos).\n",
    "Use the provided [**get-additional-demos.sh**](./get-additional-demos.sh) script to get updated demos from this repository.\n",
    "By default, the script retrieves the files from the latest release that matches the version of the installed `mlrun` package (see [Installing and Updating the MLRun Python Package](#mlrun-python-pkg-install-n-update)).\n",
    "The files are copied to the **/v3io/users/&lt;username&gt;/demos** directory, where `<username>` is the name of the running user (`$V3IO_USERNAME`) unless you set the `-u|--user` flag to another username.\n",
    "> **Note:** Before running the script, close any open files in the **demos** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get additional demos\n",
    "!/User/get-additional-demos.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full usage instructions, run the script with the `-h` or `--help` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/User/get-additional-demos.sh --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr align=\"left\">\n",
    "    <th>Demo</th>\n",
    "    <th/>\n",
    "    <th/>\n",
    "    <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>scikit-learn Demo: Full AutoML Pipeline</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/scikit-learn-pipeline/sklearn-project.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/blob/master/scikit-learn-pipeline/\">\n",
    "                <img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates how to build a full end-to-end automated-ML (AutoML) pipeline using <a href=\"https://scikit-learn.org\">scikit-learn</a> and the UCI <a href=\"http://archive.ics.uci.edu/ml/datasets/iris\">Iris data set</a>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Image Classification with Distributed Training Demo</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/image-classification-with-distributed-training/horovod-project.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/tree/master/image-classification-with-distributed-training/\">\n",
    "                <img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates an end-to-end image-classification solution using <a href=\"https://www.tensorflow.org/\">TensorFlow</a> (versions 1 or 2), <a href=\"https://keras.io/\">Keras</a>, <a href=\"https://eng.uber.com/horovod/\">Horovod</a>, and <a href=\"https://nuclio.io/\">Nuclio</a>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Faces Demo: Real-Time Image Recognition with Deep Learning</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/realtime-face-recognition/notebooks/face-recognition.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/tree/master/realtime-face-recognition/\"><img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates real-time capture, recognition, and classification of face images over a video stream, as well as location tracking of identities, using <a href=\"https://pytorch.org/\">PyTorch</a>, <a href=\"https://opencv.org/\">OpenCV</a>, and <a href=\"https://www.streamlit.io/\">Streamlit</a>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Churn Demo: Real-Time Customer-Churn Prediction</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/customer-churn-prediction/churn-project.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/tree/master/customer-churn-prediction/\"><img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates analysis of customer-churn data using the Kaggle <a href=\"https://www.kaggle.com/blastchar/telco-customer-churn\" rel=\"nofollow\">Telco Customer Churn data set</a>, model training and validation using <a href=\"https://xgboost.readthedocs.io/\" rel=\"nofollow\">XGBoost</a>, and model serving using real-time Nuclio serverless functions.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Stock-Analysis Demo</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/stock-analysis/project.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/tree/master/stock-analysis/\"><img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates how to tackle a common requirement of running a data-engineering pipeline as part of ML model serving by reading data from external data sources and generating insights using ML models.\n",
    "            The demo reads stock data from an external source, analyzes the related market news, and visualizes the analyzed data in a Grafana dashboard.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>NetOps Demo: Predictive Network Operations / Telemetry</b></td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a href=\"demos/network-operations/project.ipynb\"><img src=\"./assets/images/Jupyter-Logo-32px.png\"/><br>Open locally</a>\n",
    "        </td>\n",
    "        <td align=\"center\", style=\"min-width:45px; padding: 10px;\">\n",
    "            <a target=\"_blank\" href=\"https://github.com/mlrun/demos/tree/master/network-operations/\"><img src=\"./assets/images/GitHub-Mark-32px.png\"/><br>View on GitHub</a>\n",
    "        </td>\n",
    "        <td>Demonstrates how to build an automated ML pipeline for predicting network outages based on network-device telemetry, also known as Network Operations (NetOps).\n",
    "            The demo implements both model training and inference, including model monitoring and concept-drift detection.\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mlrun-python-pkg-install-n-update\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Updating the MLRun Python Package\n",
    "\n",
    "The demo applications and many of the platform tutorials use [MLRun](https://github.com/mlrun/mlrun) &mdash; Iguazio's end-to-end open-source MLOps solution for managing and automating your entire analytics and machine-learning life cycle, from data ingestion through model development to full pipeline deployment in production.\n",
    "MLRun is available in the platform via a default (pre-deployed) shared platform service (`mlrun`).\n",
    "However, to use MLRun from Python code (such as in the demo and tutorial notebooks), you also need to install the [MLRun Python package](https://readthedocs.org/projects/mlrun/) (`mlrun`).\n",
    "The version of the installed package must match the version of the platform's MLRun service and must be updated whenever the service's version is updated.\n",
    "\n",
    "The platform provides an [**align_mlrun.sh**](./align_mlrun.sh) script for simplifying the MLrun package installation and version synchronization with the MLRun service.\n",
    "The script is available in the running-user directory (your Jupyter home directory), which is accessible via the **/User** data mount.\n",
    "Use the following command to run this script for the initial package installation (after creating a new Jupyter Notebook service) and whenever the MLRun service is updated; (the command should be run for each Jupyter Notebook service):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-ingestion-and-preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Preparation\n",
    "\n",
    "The platform allows storing data in any format.\n",
    "The platform's multi-model data layer and related APIs provide enhanced support for working with NoSQL (\"key-value\"), time-series, and stream data.\n",
    "Various steps of the data science life cycle (pipeline) might require different tools and frameworks for working with data, especially when it comes to the different mechanisms required during the research and development phase versus the operational production phase.\n",
    "The platform features a wide array of methods for manipulating and managing data, of different formats, in each step of the data life cycle, using a variety of frameworks, tools, and APIs &mdash; such as as the following:\n",
    "\n",
    "- Spark SQL and DataFrames\n",
    "- Spark Streaming\n",
    "- Presto SQL queries\n",
    "- pandas DataFrames\n",
    "- Dask\n",
    "- V3IO Frames Python library\n",
    "- V3IO SDK\n",
    "- Web APIs\n",
    "\n",
    "The data ingestion and preparation tutorial README (**data-ingestion-and-preparation/README.ipynb/.md**) provides an overview of various methods for collecting, storing, and manipulating data in the platform, and references to sample tutorial notebooks that demonstrate how to use these methods.\n",
    "<br>\n",
    "**&#x25B6; [Open the README notebook](./data-ingestion-and-preparation/README.ipynb) / [Markdown file](data-ingestion-and-preparation/README.md)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platform-resources\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Platform Resources\n",
    "\n",
    "You can find more information and resources in the MLRun documentation:\n",
    "<br>\n",
    "**&#x25B6; [View the MLRun documentation](https://mlrun.readthedocs.io)**\n",
    "\n",
    "You might also find the folloiwng resources useful:\n",
    "\n",
    "- [Introduction video](https://www.youtube.com/watch?v=8OmAN4wd7To)\n",
    "- [In-depth platform overview](platform-overview.ipynb) with a break down of the steps for developing a full data science workflow from development to production\n",
    "- [Platform components, services, and development ecosystem introduction](https://www.iguazio.com/docs/latest-release/intro/ecosystem/)\n",
    "- [Platform references](https://iguazio.com/docs/latest-release/reference/)\n",
    "- [nuclio-jupyter SDK](https://github.com/nuclio/nuclio-jupyter/blob/master/README.md) for creating and deploying Nuclio functions with Python and Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"misc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creating-virtual-environments-in-jupyter-notebook\"></a>\n",
    "### Creating Virtual Environments in Jupyter Notebook\n",
    "\n",
    "A virtual environment is a named, isolated, working copy of Python that maintains its own files, directories, and paths so that you can work with specific versions of libraries or Python itself without affecting other Python projects.\n",
    "Virtual environments make it easy to cleanly separate projects and avoid problems with different dependencies and version requirements across components.\n",
    "See the [virtual-env](virtual-env.ipynb) tutorial notebook for step-by-step instructions for using conda to create your own Python virtual environments, which will appear as custom kernels in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"update-notebooks\"></a>\n",
    "### Updating the Tutorial Notebooks\n",
    "\n",
    "You can use the provided **igz-tutorials-get.sh** script to get updated platform tutorials from the [tutorials GitHub repository](https://github.com/v3io/tutorials/).\n",
    "By default, the script retrieves the files from the latest release that matches the current platform version.\n",
    "For details, see the [**update-tutorials.ipynb**](update-tutorials.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"v3io-dir\"></a>\n",
    "### The v3io Directory\n",
    "\n",
    "The **v3io** directory that you see in the file browser of the Jupyter UI displays the contents of the `v3io` data mount for browsing the platform data containers.\n",
    "For information about the predefined data containers and data mounts and how to reference data in these containers, see [Platform Data Containers](data-ingestion-and-preparation/README.ipynb#platform-data-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"support\"></a>\n",
    "### Support\n",
    "\n",
    "The Iguazio [support team](mailto:support@iguazio.com) will be happy to assist with any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
